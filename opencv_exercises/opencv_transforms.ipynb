{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92aa774c-04cc-477f-8f63-f75c7b74da68",
   "metadata": {},
   "source": [
    "## Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a90d01d7-1eb2-4bbe-bc94-f8a77a1be35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa67a103-2094-435e-ab42-aedc6f88b3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('data/lena.png')\n",
    "b,g,r = cv2.split(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b377094-96fa-4161-b19d-707606507080",
   "metadata": {},
   "source": [
    "### Splitting channels - reconstructing the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0753ec08-3ecb-4b40-876b-47c418591d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = np.hstack([b,g,r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37f9f53a-412b-4d81-aee5-5a6462a886b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow('Blue',b)\n",
    "# cv2.imshow('Green',g)\n",
    "# cv2.imshow('Red',r) #instead use the one below - the images will be on the one window\n",
    "\n",
    "cv2.imshow('Channel',channels)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#observations - the red seems the lightest (white on black, i mean grayscale) because this channel has bigger values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdf7707-9b22-4f1e-a099-c833ea043371",
   "metadata": {},
   "source": [
    "### Treat img as numpy array (another aprroach FASTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "622c8d80-bf09-4957-afe9-dbda464d7e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = img[:,:,0] #treating the image as numpy array. blue first channel index 0, green second channel index 1...\n",
    "g = img[:,:,1] \n",
    "r = img[:,:,2] \n",
    "\n",
    "cv2.imshow('Blue - as numpy. the same result',b)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe46523-e7d7-4f91-8847-de47d9d98525",
   "metadata": {},
   "source": [
    "### Merge the channels to make image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ed3bf72-edbc-44c8-b440-7d4783875cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img = cv2.merge((b,g,r))\n",
    "\n",
    "cv2.imshow('Channel',new_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7a048e-3c82-44f9-9388-984557e5b7ce",
   "metadata": {},
   "source": [
    "### Geometrical transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222de6bc-8bc1-4a43-8db2-dc8abd7be9a7",
   "metadata": {},
   "source": [
    "#### Changing the scale of an image - resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8958909-8f60-40d2-8bd8-892cb4576909",
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_img = cv2.resize(img,(200,200), interpolation=cv2.INTER_LINEAR) #new size of the image SMALL\n",
    "#wtf is  interpolation: algorithm that fills the missing data:)\n",
    "\n",
    "cv2.imshow('Resized lena',resized_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "126e474d-ecb8-404f-bc1f-df85f16e6e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_img = cv2.resize(img,(1000,1000), interpolation=cv2.INTER_LINEAR) #new size of the image BIG\n",
    "cv2.imshow('Resized lena',resized_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a38d8fe-2085-4e64-94d8-ea30e2e0a0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stretch\n",
    "resized_img = cv2.resize(img,(300,500), interpolation=cv2.INTER_LINEAR)\n",
    "cv2.imshow('Resized lena',resized_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54244105-2dcc-4feb-bb48-2cad9ee55223",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale 0.5x and 0.7x - so make smaller half from the original size\n",
    "resized_img = cv2.resize(img,None, fx=0.5, fy=0.7, interpolation=cv2.INTER_LINEAR)\n",
    "cv2.imshow('Resized lena',resized_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0369a87-3815-4e22-a141-10751c51df8e",
   "metadata": {},
   "source": [
    "#### Translation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfa5eda1-63b2-4082-99b6-3afb36e78d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 0 tx\\n0 1 ty'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''1 0 tx\n",
    "0 1 ty'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3902ddda-d3e5-48c0-af95-75d85170e0c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M = np.float32([\\n    [1,0,tx],\\n    [0,1,ty]\\n])'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''M = np.float32([\n",
    "    [1,0,tx],\n",
    "    [0,1,ty]\n",
    "])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "870a768e-b525-4a6d-94b7-61282e23b18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.float32([ #float32 is ok to make transformation\n",
    "    [1,0,200],\n",
    "    [0,1,50]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6a02c97-b986-4be7-a559-3f68a247433b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the matrix to our image\n",
    "h,w = img.shape[:2]                         #height, width usually given in this order\n",
    "new_img = cv2.warpAffine(img,M,(w,h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a18d698-41a5-4480-8df8-bbe8f6146561",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Translated',new_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#REsult - translated image. by 200px on OX, 50px on OY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65968f91-0f02-45df-ba6f-cdf1fb740c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img = cv2.warpAffine(img,M,(1024,1024)) #destination space (height,width) is bigger and we fit image:) and we dont lose some info\n",
    "# if the window size wouldnt be defined, then it will remain as the size of the original image, with applied translation\n",
    "cv2.imshow('Translated',new_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2a51ac4b-c80a-40ff-ada8-ba414372e173",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.float32([ \n",
    "    [1,0,0], #negative numbers make it move to another way:) \n",
    "    [0,1,-200]\n",
    "])\n",
    "h,w = img.shape[:2]  \n",
    "new_img = cv2.warpAffine(img,M,(500,500))\n",
    "cv2.imshow('Transformed',new_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507513df-4f7d-4349-9c18-52923d3ec746",
   "metadata": {},
   "source": [
    "#### Rotation matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436c34a6-1bb9-47e1-a173-0907d1a8056a",
   "metadata": {},
   "source": [
    "alfa beta (1-alfa) * center.x - beta * center.y ||||\n",
    "-beta alfa beta * center.x + (1-alfa) * center.y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754f7e75-2bd8-4092-a3f1-af31c4120703",
   "metadata": {},
   "source": [
    "alfa = scale * cosAngle ||||\n",
    "beta = scale * sinAngle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "843cc3f7-5fa0-4608-b522-ce31f667d7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WE can pick a center, or any point that will be the the pivot for our rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d954f1fc-6a2e-4ea0-ac46-7be8b35ab6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "h,w = img.shape[:2] #h,w of original img\n",
    "\n",
    "#compute the rotation matrix\n",
    "M = cv2.getRotationMatrix2D((h//2.0,w//2.0),180,1) #180 - we rotate it 180 degrees, 1 - scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0978d352-b9a2-4ca4-bd7b-de1ce85c3402",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the rotation to the original img\n",
    "new_img = cv2.warpAffine(img,M,(h,w))\n",
    "\n",
    "cv2.imshow('Rotated lena',new_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() #WOW we rotated image oooooh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ea8ca8e9-1457-43b5-8dcb-7544d5bcac21",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = cv2.getRotationMatrix2D((h//2.0,w//2.0),45,2) \n",
    "new_img = cv2.warpAffine(img,M,(h,w))\n",
    "\n",
    "cv2.imshow('Rotated lena',new_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "#We scaled and rotated but we still cant contain all the pixels in the window:("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a74619e8-8db2-4581-9a6b-ad91ecc6fcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our pic has to have the same size af original and we want not to lose all the info. So we use the SCALE.\n",
    "M = cv2.getRotationMatrix2D((h//2.0,w//2.0),45,0.7) \n",
    "new_img = cv2.warpAffine(img,M,(h,w))\n",
    "\n",
    "cv2.imshow('Rotated lena',new_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc0b259-9989-45d0-af31-3b25a053562a",
   "metadata": {},
   "source": [
    "What if we have final image and we want to know the matrix of transformation, that has been applied for the original image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4601f1ed-442a-4153-bb95-0935a3531e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.08108108 -3.64864865]\n",
      " [ 0.          1.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "pts_1 = np.float32([\n",
    "    [135,45],\n",
    "    [385,45],\n",
    "    [135,230]\n",
    "])\n",
    "\n",
    "pts_2 = np.float32([\n",
    "    [135,45],\n",
    "    [385,45],\n",
    "    [150,230]\n",
    "])\n",
    "\n",
    "#get the matrix M tat transforms pts1 to pts2.\n",
    "M = cv2.getAffineTransform(pts_1,pts_2)\n",
    "print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "40e663e5-e493-4f09-a677-378276fc4fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img = cv2.warpAffine(pts_1,M,(1024,1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62114db-0ce0-4995-bf2e-1e18cc58f622",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
